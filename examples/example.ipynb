{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29335f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02dd8b7c",
   "metadata": {},
   "source": [
    "## **Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff03174",
   "metadata": {},
   "outputs": [],
   "source": [
    "!accelerate launch --config_file \"deepspeed_config_z3_qlora.yaml\"  trainLLM.py \\\n",
    "--model_name_or_path \"meta-llama/Llama-3.1-8B\" \\\n",
    "--dataset_name \"ccdv/pubmed-summarization\" \\\n",
    "--dataset_path \"path\" \\\n",
    "--output_dir \"path\" \\\n",
    "--tokenized_dataset_path \"path\" \\\n",
    "--resume_from_checkpoint \"path\" \\\n",
    "--dataset_text_field \"article\" \\\n",
    "--chat_template_format \"none\" \\\n",
    "--max_seq_length 2048 \\\n",
    "--bf16 True \\\n",
    "--num_train_epochs 1 \\\n",
    "--learning_rate 1e-5 \\\n",
    "--lr_scheduler_type \"linear\" \\\n",
    "--weight_decay 1e-5 \\\n",
    "--warmup_ratio 0.0 \\\n",
    "--gradient_accumulation_steps 2 \\\n",
    "--gradient_checkpointing True \\\n",
    "--max_grad_norm 1.0 \\\n",
    "--per_device_train_batch_size 4 \\\n",
    "--per_device_eval_batch_size 8 \\\n",
    "--logging_steps 10 \\\n",
    "--log_level \"info\" \\\n",
    "--logging_strategy \"steps\" \\\n",
    "--save_strategy \"steps\" \\\n",
    "--save_steps 100\\\n",
    "--eval_strategy \"steps\" \\\n",
    "--eval_steps 100 \\\n",
    "--add_special_tokens False \\\n",
    "--append_concat_token False \\\n",
    "--packing True \\\n",
    "--use_reentrant True \\\n",
    "--use_flash_attn True \\\n",
    "--seed 100 \\\n",
    "--use_peft_lora False \\\n",
    "--lora_r 8 \\\n",
    "--lora_alpha 16 \\\n",
    "--lora_dropout 0.1 \\\n",
    "--lora_target_modules \"all-linear\" \\\n",
    "--use_4bit_quantization False \\\n",
    "--use_nested_quant False \\\n",
    "--bnb_4bit_compute_dtype \"bfloat16\" \\\n",
    "--bnb_4bit_quant_storage_dtype \"bfloat16\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab5f4afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "!accelerate launch --config_file \"deepspeed_config_z3_qlora.yaml\"  trainLLM.py \\\n",
    "--model_name_or_path \"Qwen/Qwen2.5-7B\" \\\n",
    "--dataset_name \"Malikeh1375/medical-question-answering-datasets\" \\\n",
    "--dataset_path \"path\" \\\n",
    "--output_dir \"path\" \\\n",
    "--splits \"train\" \\\n",
    "--dataset_text_field \"text\" \\\n",
    "--chat_template_format \"qwen2.5\" \\\n",
    "--max_seq_length 2048 \\\n",
    "--bf16 True \\\n",
    "--num_train_epochs 1 \\\n",
    "--learning_rate 1e-5 \\\n",
    "--lr_scheduler_type \"linear\" \\\n",
    "--weight_decay 1e-5 \\\n",
    "--warmup_ratio 0.0 \\\n",
    "--gradient_accumulation_steps 2 \\\n",
    "--gradient_checkpointing True \\\n",
    "--max_grad_norm 1.0 \\\n",
    "--per_device_train_batch_size 2 \\\n",
    "--per_device_eval_batch_size 4 \\\n",
    "--logging_steps 10 \\\n",
    "--log_level \"info\" \\\n",
    "--logging_strategy \"steps\" \\\n",
    "--save_strategy \"steps\" \\\n",
    "--save_steps 100\\\n",
    "--eval_strategy \"steps\" \\\n",
    "--eval_steps 0.1 \\\n",
    "--add_special_tokens False \\\n",
    "--append_concat_token False \\\n",
    "--packing True \\\n",
    "--use_reentrant True \\\n",
    "--use_flash_attn True \\\n",
    "--seed 100 \\\n",
    "--use_peft_lora False \\\n",
    "--lora_r 8 \\\n",
    "--lora_alpha 16 \\\n",
    "--lora_dropout 0.1 \\\n",
    "--lora_target_modules \"all-linear\" \\\n",
    "--use_4bit_quantization False \\\n",
    "--use_nested_quant False \\\n",
    "--bnb_4bit_compute_dtype \"bfloat16\" \\\n",
    "--bnb_4bit_quant_storage_dtype \"bfloat16\" \\\n",
    "--tokenized_dataset_path \"path\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab34c817",
   "metadata": {},
   "source": [
    "## **Checkpoint Merge**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f9d3923",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python merge_checkpoint.py \\"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33ac0964",
   "metadata": {},
   "source": [
    "# **Benchmark**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde21884",
   "metadata": {},
   "outputs": [],
   "source": [
    "!accelerate launch --multi_gpu --num_processes 8 \\\n",
    "    -m lm_eval --model hf \\\n",
    "    --model_args pretrained=\"/lvs0/rccs-hpbdrt/minqiu/Model_output/Qwen2.5-7B-medqa-merge_parity\"\\\n",
    "    --tasks medmcqa,medqa_4options,pubmedqa,mmlu \\\n",
    "    --batch_size 16 \\\n",
    "    --trust_remote_code \\\n",
    "    --output_path output/Llama3.2-1B \\\n",
    "    --log_samples"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
